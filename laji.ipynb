{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0735f1b-33f2-4372-9514-ce9b26fe3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f4b632-bba8-4078-a798-62b3ae11ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f56e6a0b-b99f-4896-a054-2ca2190ef56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                # 读取图像\n",
    "                img = cv2.imread(img_path)\n",
    "                # 调整图像大小\n",
    "                img = cv2.resize(img, IMG_SIZE)\n",
    "                # 将图像添加到列表中\n",
    "                images.append(img)\n",
    "                # 添加标签\n",
    "                labels.append(folder)\n",
    "    # 将标签转换为数字\n",
    "    label_to_id = {'O': 0, 'R': 1}\n",
    "    labels = [label_to_id[label] for label in labels]\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430d01c1-cc81-4f87-b081-a102c898f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_dataset('C:/Users/35468/data/test')\n",
    "test_images, test_labels = load_dataset('C:/Users/35468/data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bba56a4-ced1-4960-9b3e-13ac4494eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bc9c7d8-db5c-428d-a2a8-4f4b213275cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7da24d1d-2a93-4dec-84c5-015dd8ba8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec36aac-ae74-460a-9134-5579822c3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet50v2_model():\n",
    "    base_model = ResNet50V2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "670704fa-3d82-4db0-9a07-00d7087e54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50v2_model = create_resnet50v2_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95426fd7-dadc-4bee-9b06-0be91ac4844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f854e65e-d51a-44c3-9777-b414411fb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape=(224, 224, 3)):\n",
    "    # 创建一个 Sequential 模型\n",
    "    model = Sequential([\n",
    "        # 添加卷积层\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2,2)),\n",
    "        # 添加卷积层\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D((2,2)),\n",
    "        # 添加卷积层\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D((2,2)),\n",
    "        # 添加 Flatten 层\n",
    "        Flatten(),\n",
    "        # 添加全连接层\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        # 添加输出层\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46c545e2-7411-413d-84bc-464cf673d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = create_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f2b7fed-a58d-461f-8d5d-46c2778f97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 114s 12s/step - loss: 0.2983 - accuracy: 0.9100 - val_loss: 1.3130 - val_accuracy: 0.5635\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 106s 12s/step - loss: 0.0386 - accuracy: 0.9933 - val_loss: 2.1406 - val_accuracy: 0.5412\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 107s 12s/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.5808 - val_accuracy: 0.5365\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 110s 12s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.5353\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 110s 12s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.1806 - val_accuracy: 0.5271\n"
     ]
    }
   ],
   "source": [
    "history_resnet50v2 = resnet50v2_model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d02df11-f417-4bd2-867b-23ed3850c31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 28s 3s/step - loss: 1.0014 - accuracy: 0.6800 - val_loss: 0.4436 - val_accuracy: 0.7976\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.4266 - accuracy: 0.8867 - val_loss: 0.4740 - val_accuracy: 0.8424\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.2121 - accuracy: 0.9233 - val_loss: 0.4597 - val_accuracy: 0.8206\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.1522 - accuracy: 0.9633 - val_loss: 0.4672 - val_accuracy: 0.8406\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.1642 - accuracy: 0.9433 - val_loss: 0.5344 - val_accuracy: 0.8153\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4cbfd9e-dabc-4db9-bba0-5830c8971324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 94s 2s/step - loss: 3.1806 - accuracy: 0.5271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1805543899536133, 0.5270588397979736]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50v2_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5135a6ff-d388-4b9e-9f77-63e4bd2fd75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 17s 311ms/step - loss: 0.5344 - accuracy: 0.8153\n",
      "CNN 模型的准确率: 81.53%\n"
     ]
    }
   ],
   "source": [
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(test_images, test_labels)\n",
    "print(\"CNN 模型的准确率: {:.2f}%\".format(cnn_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c99f4f4-ded9-4e96-97da-93c52c62888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d427d8-aa7a-4bcd-88dc-153b553bbb4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Sequential' and 'Sequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-091a67a59f31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresnet50v2_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mmodel12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Sequential' and 'Sequential'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c24399",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('laji.pkl','wb') as f:\n",
    "    pickle.dump(cnn_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bb8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
